{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deepfake Detection Pipeline\n",
        "\n",
        "This notebook demonstrates the complete deepfake detection pipeline:\n",
        "1. Video frame extraction\n",
        "2. Face detection and cropping\n",
        "3. Multi-detector analysis (CNN, Temporal, Lip-Sync, Frequency)\n",
        "4. Ensemble fusion\n",
        "5. Result visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Any, List, Optional\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import uuid\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Optional\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Import project modules\n",
        "import backend.utils.file_utils as file_utils\n",
        "import backend.utils.video_utils as video_utils\n",
        "import backend.utils.face_utils as face_utils\n",
        "import backend.utils.mouth_cropper as mouth_cropper\n",
        "import backend.utils.temporal_utils as temporal_utils\n",
        "import backend.utils.aggregation as aggregation\n",
        "import backend.utils.ensemble as ensemble\n",
        "from backend.utils.model_cache import model_cache\n",
        "from backend.utils.abnormality_analyzer import AbnormalityAnalyzer\n",
        "from backend.utils.technique_identifier import TechniqueIdentifier\n",
        "\n",
        "print(\"✓ All imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model cache (pre-loads all models)\n",
        "print(\"Initializing models...\")\n",
        "model_cache.initialize()\n",
        "print(\"✓ Models initialized\")\n",
        "\n",
        "# Get detectors\n",
        "cnn_detector = model_cache.get_cnn_detector()\n",
        "temporal_detector = model_cache.get_temporal_detector()\n",
        "lipsync_detector = model_cache.get_lipsync_detector()\n",
        "freq_detector = model_cache.get_frequency_detector()\n",
        "\n",
        "print(\"✓ All detectors loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Video\n",
        "\n",
        "**Note:** Update the path to your video file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Automatically find a video file in storage/uploads\n",
        "# You can also specify a custom path: video_path = \"storage/uploads/your_video.mp4\"\n",
        "\n",
        "uploads_dir = Path(\"storage/uploads\")\n",
        "video_path = None\n",
        "\n",
        "# Try to find an MP4 file\n",
        "if uploads_dir.exists():\n",
        "    video_files = list(uploads_dir.glob(\"*.mp4\"))\n",
        "    if video_files:\n",
        "        # Use the first available video\n",
        "        video_path = str(video_files[0])\n",
        "        print(f\"✓ Found video: {video_path}\")\n",
        "        file_size = Path(video_path).stat().st_size / (1024 * 1024)  # MB\n",
        "        print(f\"  File size: {file_size:.2f} MB\")\n",
        "        print(f\"  Total videos available: {len(video_files)}\")\n",
        "    else:\n",
        "        print(f\"⚠ No MP4 files found in {uploads_dir}\")\n",
        "        print(\"Please add a video file to storage/uploads/\")\n",
        "else:\n",
        "    print(f\"⚠ Directory not found: {uploads_dir}\")\n",
        "    print(\"Please create the directory and add a video file\")\n",
        "\n",
        "# If no video found, set a placeholder (will skip processing)\n",
        "if video_path is None:\n",
        "    video_path = \"storage/uploads/your_video.mp4\"\n",
        "    print(f\"\\n⚠ Using placeholder path: {video_path}\")\n",
        "    print(\"Update this cell with a valid video path to run the analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Extract Frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if video exists before processing\n",
        "if not Path(video_path).exists() or \"your_video.mp4\" in video_path:\n",
        "    print(\"⚠ Skipping frame extraction - no valid video file\")\n",
        "    print(\"Please update the video_path in the previous cell\")\n",
        "    frame_count = 0\n",
        "    job_id = None\n",
        "else:\n",
        "    # Generate unique job ID\n",
        "    job_id = str(uuid.uuid4())\n",
        "    print(f\"Job ID: {job_id}\")\n",
        "    \n",
        "    # Setup directories\n",
        "    base_dir = os.path.abspath(\"storage\")\n",
        "    frames_output_dir = os.path.normpath(os.path.join(base_dir, \"frames\", job_id))\n",
        "    \n",
        "    # Extract frames (1 frame per second)\n",
        "    print(\"\\nExtracting frames...\")\n",
        "    try:\n",
        "        frame_count = video_utils.extract_frames(\n",
        "            video_path=video_path,\n",
        "            output_dir=frames_output_dir,\n",
        "            fps=1\n",
        "        )\n",
        "        print(f\"✓ Extracted {frame_count} frames\")\n",
        "        \n",
        "        # Display first frame\n",
        "        if frame_count > 0:\n",
        "            from PIL import Image\n",
        "            first_frame = list(Path(frames_output_dir).glob(\"frame_*.jpg\"))[0]\n",
        "            img = Image.open(first_frame)\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"First Frame (Total: {frame_count} frames)\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Error extracting frames: {e}\")\n",
        "        frame_count = 0\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Extract Faces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract faces from frames\n",
        "if job_id is None or frame_count == 0:\n",
        "    print(\"⚠ Skipping face extraction - no frames available\")\n",
        "    face_count = 0\n",
        "else:\n",
        "    faces_output_dir = os.path.normpath(os.path.join(base_dir, \"faces\", job_id))\n",
        "    \n",
        "    print(\"Extracting faces...\")\n",
        "    try:\n",
        "        face_count = face_utils.extract_faces_from_frames(\n",
        "            frames_dir=frames_output_dir,\n",
        "            output_dir=faces_output_dir\n",
        "        )\n",
        "        print(f\"✓ Extracted {face_count} faces\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Error extracting faces: {e}\")\n",
        "        face_count = 0\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Display sample faces\n",
        "if face_count > 0:\n",
        "    face_files = sorted(Path(faces_output_dir).glob(\"face_*.jpg\"))[:6]  # Show first 6\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, face_path in enumerate(face_files):\n",
        "        img = Image.open(face_path)\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].set_title(f\"Face {idx+1}\")\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    # Hide unused subplots\n",
        "    for idx in range(len(face_files), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run CNN Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run CNN detection on all faces\n",
        "# Initialize variables if not set\n",
        "if 'face_count' not in locals():\n",
        "    face_count = 0\n",
        "if 'job_id' not in locals():\n",
        "    job_id = None\n",
        "if 'base_dir' not in locals():\n",
        "    base_dir = os.path.abspath(\"storage\")\n",
        "if 'faces_output_dir' not in locals() and job_id:\n",
        "    faces_output_dir = os.path.normpath(os.path.join(base_dir, \"faces\", job_id))\n",
        "else:\n",
        "    faces_output_dir = None\n",
        "\n",
        "detections: List[Dict[str, Any]] = []\n",
        "\n",
        "if face_count > 0 and faces_output_dir and Path(faces_output_dir).exists():\n",
        "    print(\"Running CNN detection...\")\n",
        "    face_files = sorted(Path(faces_output_dir).glob(\"face_*.jpg\"))\n",
        "    face_paths = [str(f) for f in face_files]\n",
        "    \n",
        "    # Use batch prediction if available (much faster)\n",
        "    if hasattr(cnn_detector, 'predict_batch'):\n",
        "        print(f\"Using batch processing for {len(face_paths)} faces\")\n",
        "        fake_scores = cnn_detector.predict_batch(face_paths)\n",
        "    else:\n",
        "        print(f\"Using individual predictions for {len(face_paths)} faces\")\n",
        "        fake_scores = [cnn_detector.predict(path) for path in face_paths]\n",
        "    \n",
        "    # Create detections list\n",
        "    for idx, (face_path, fake_score) in enumerate(zip(face_files, fake_scores)):\n",
        "        detections.append({\n",
        "            \"face_file\": face_path.name,\n",
        "            \"frame\": idx + 1,\n",
        "            \"fake_score\": round(fake_score, 4)\n",
        "        })\n",
        "    \n",
        "    # Sort by highest fake_score (most suspicious first)\n",
        "    detections.sort(key=lambda x: x[\"fake_score\"], reverse=True)\n",
        "    \n",
        "    print(f\"✓ Processed {len(detections)} faces\")\n",
        "    print(f\"  Max score: {max(fake_scores):.4f}\")\n",
        "    print(f\"  Mean score: {np.mean(fake_scores):.4f}\")\n",
        "    \n",
        "    # Visualize scores\n",
        "    scores = [d[\"fake_score\"] for d in detections]\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(scores, bins=20, edgecolor='black', alpha=0.7)\n",
        "    plt.xlabel('Fake Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of CNN Fake Scores')\n",
        "    plt.axvline(x=0.5, color='r', linestyle='--', label='Threshold (0.5)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"⚠ No faces detected\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run Frequency Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute frequency scores for all faces\n",
        "# Initialize variables if not set\n",
        "if 'job_id' not in locals() or job_id is None:\n",
        "    job_id = str(uuid.uuid4()) if 'uuid' in dir() else \"test\"\n",
        "if 'results_dir' not in locals():\n",
        "    results_dir = os.path.abspath(\"results\")\n",
        "if 'faces_output_dir' not in locals():\n",
        "    faces_output_dir = None\n",
        "\n",
        "frequency_debug_dir = os.path.normpath(os.path.join(results_dir, job_id, \"frequency_maps\"))\n",
        "freq_scores_dict = {}\n",
        "\n",
        "if face_count > 0 and faces_output_dir and Path(faces_output_dir).exists():\n",
        "    print(\"Running frequency detection...\")\n",
        "    freq_scores_dict = freq_detector.batch_compute(\n",
        "        faces_dir=faces_output_dir,\n",
        "        output_debug_dir=frequency_debug_dir\n",
        "    )\n",
        "    \n",
        "    # Add frequency scores to detections\n",
        "    for detection in detections:\n",
        "        face_filename = detection[\"face_file\"]\n",
        "        freq_score = freq_scores_dict.get(face_filename, 0.5)\n",
        "        detection[\"freq_score\"] = round(freq_score, 4)\n",
        "    \n",
        "    freq_scores = list(freq_scores_dict.values())\n",
        "    print(f\"✓ Computed frequency scores for {len(freq_scores)} faces\")\n",
        "    print(f\"  Mean frequency score: {np.mean(freq_scores):.4f}\")\n",
        "    print(f\"  Max frequency score: {max(freq_scores):.4f}\")\n",
        "else:\n",
        "    print(\"⚠ No faces to analyze\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Extract Mouth Regions and Run Lip-Sync Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract mouth regions\n",
        "# Initialize variables if not set\n",
        "if 'job_id' not in locals() or job_id is None:\n",
        "    job_id = str(uuid.uuid4()) if 'uuid' in dir() else \"test\"\n",
        "if 'base_dir' not in locals():\n",
        "    base_dir = os.path.abspath(\"storage\")\n",
        "if 'face_count' not in locals():\n",
        "    face_count = 0\n",
        "if 'faces_output_dir' not in locals():\n",
        "    faces_output_dir = None\n",
        "\n",
        "mouth_output_dir = os.path.normpath(os.path.join(base_dir, \"mouth\", job_id))\n",
        "mouth_count = 0\n",
        "lip_sync_score = None\n",
        "\n",
        "if face_count > 0 and faces_output_dir and Path(faces_output_dir).exists():\n",
        "    print(\"Extracting mouth regions...\")\n",
        "    mouth_count = mouth_cropper.extract_mouth_frames(\n",
        "        faces_dir=faces_output_dir,\n",
        "        output_dir=mouth_output_dir\n",
        "    )\n",
        "    print(f\"✓ Extracted {mouth_count} mouth regions\")\n",
        "    \n",
        "    # Extract audio from video\n",
        "    audio_output_path = os.path.normpath(os.path.join(base_dir, \"audio\", f\"{job_id}.wav\"))\n",
        "    \n",
        "    try:\n",
        "        print(\"\\nExtracting audio...\")\n",
        "        lipsync_detector.extract_audio(video_path=video_path, out_wav=audio_output_path)\n",
        "        print(f\"✓ Audio extracted to: {audio_output_path}\")\n",
        "        \n",
        "        # Compute lip-sync score\n",
        "        print(\"\\nComputing lip-sync score...\")\n",
        "        lip_sync_score = lipsync_detector.compute_sync_score(\n",
        "            mouth_frames_dir=mouth_output_dir,\n",
        "            audio_path=audio_output_path\n",
        "        )\n",
        "        print(f\"✓ Lip-sync score: {lip_sync_score:.4f}\")\n",
        "        print(f\"  (Lower score = more suspicious)\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Error in lip-sync analysis: {e}\")\n",
        "        lip_sync_score = None\n",
        "else:\n",
        "    print(\"⚠ No faces to analyze\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Run Temporal Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run temporal detection on face tracks\n",
        "# Initialize variables if not set\n",
        "if 'face_count' not in locals():\n",
        "    face_count = 0\n",
        "if 'faces_output_dir' not in locals():\n",
        "    faces_output_dir = None\n",
        "\n",
        "temporal_mean = 0.5\n",
        "temporal_max = 0.5\n",
        "\n",
        "if face_count > 0 and faces_output_dir and Path(faces_output_dir).exists():\n",
        "    try:\n",
        "        print(\"Running temporal detection...\")\n",
        "        # Group faces into tracks\n",
        "        tracks = temporal_utils.group_faces_into_tracks(faces_output_dir)\n",
        "        print(f\"  Found {len(tracks)} face tracks\")\n",
        "        \n",
        "        track_scores = []\n",
        "        for track in tracks:\n",
        "            track_result = temporal_detector.predict_for_face_track(\n",
        "                frames_dir=faces_output_dir,\n",
        "                clip_len=16,\n",
        "                stride=8\n",
        "            )\n",
        "            if track_result[\"clip_scores\"]:\n",
        "                track_scores.extend(track_result[\"clip_scores\"])\n",
        "        \n",
        "        if track_scores:\n",
        "            temporal_mean = sum(track_scores) / len(track_scores)\n",
        "            temporal_max = max(track_scores)\n",
        "            print(f\"✓ Temporal analysis complete\")\n",
        "            print(f\"  Mean temporal score: {temporal_mean:.4f}\")\n",
        "            print(f\"  Max temporal score: {temporal_max:.4f}\")\n",
        "        else:\n",
        "            print(\"⚠ No temporal scores computed\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Error in temporal detection: {e}\")\n",
        "else:\n",
        "    print(\"⚠ No faces to analyze\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Aggregate Scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate all scores\n",
        "# Initialize variables if not set\n",
        "if 'detections' not in locals():\n",
        "    detections = []\n",
        "if 'lip_sync_score' not in locals():\n",
        "    lip_sync_score = None\n",
        "if 'temporal_mean' not in locals():\n",
        "    temporal_mean = 0.5\n",
        "if 'temporal_max' not in locals():\n",
        "    temporal_max = 0.5\n",
        "\n",
        "aggregation_result = aggregation.aggregate_scores(\n",
        "    detections=detections,\n",
        "    lip_sync_score=lip_sync_score,\n",
        "    temporal_mean=temporal_mean,\n",
        "    temporal_max=temporal_max\n",
        ")\n",
        "\n",
        "print(\"Aggregated Scores:\")\n",
        "print(f\"  Total faces: {aggregation_result['total_faces']}\")\n",
        "print(f\"  Max CNN score: {aggregation_result['max_score']:.4f}\")\n",
        "print(f\"  Mean CNN score: {aggregation_result['mean_score']:.4f}\")\n",
        "print(f\"  Frequency score: {aggregation_result['frequency_score']:.4f}\")\n",
        "print(f\"  Lip-sync score: {aggregation_result.get('lip_sync_score', 'N/A')}\")\n",
        "print(f\"  Temporal mean: {aggregation_result['temporal_mean']:.4f}\")\n",
        "print(f\"  Temporal max: {aggregation_result['temporal_max']:.4f}\")\n",
        "\n",
        "# Visualize aggregated scores\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Score comparison\n",
        "scores_data = {\n",
        "    'CNN Max': aggregation_result['max_score'],\n",
        "    'CNN Mean': aggregation_result['mean_score'],\n",
        "    'Frequency': aggregation_result['frequency_score'],\n",
        "    'Temporal Max': aggregation_result['temporal_max'],\n",
        "    'Temporal Mean': aggregation_result['temporal_mean']\n",
        "}\n",
        "\n",
        "if lip_sync_score is not None:\n",
        "    scores_data['Lip-Sync (inverted)'] = 1.0 - lip_sync_score\n",
        "\n",
        "axes[0].bar(scores_data.keys(), scores_data.values(), color='steelblue', alpha=0.7)\n",
        "axes[0].axhline(y=0.5, color='r', linestyle='--', label='Threshold')\n",
        "axes[0].set_ylabel('Score')\n",
        "axes[0].set_title('Detector Scores Comparison')\n",
        "axes[0].set_ylim([0, 1])\n",
        "axes[0].legend()\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# CNN scores distribution\n",
        "cnn_scores = [d['fake_score'] for d in detections]\n",
        "axes[1].hist(cnn_scores, bins=20, edgecolor='black', alpha=0.7, color='coral')\n",
        "axes[1].axvline(x=0.5, color='r', linestyle='--', label='Threshold')\n",
        "axes[1].set_xlabel('Fake Score')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('CNN Scores Distribution')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Ensemble Fusion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decide verdict using aggregation\n",
        "verdict_result = aggregation.decide_verdict(aggregation_result)\n",
        "\n",
        "# Apply ensemble combiner for final verdict\n",
        "ensemble_combiner = ensemble.EnsembleCombiner()\n",
        "ensemble_result = ensemble_combiner.combine(aggregation_result)\n",
        "\n",
        "# Update verdict with ensemble results\n",
        "if verdict_result.get(\"label\") == \"LIKELY_AUTHENTIC\":\n",
        "    if ensemble_result[\"final_score\"] < 0.6:\n",
        "        verdict_result[\"final_score\"] = ensemble_result[\"final_score\"]\n",
        "        verdict_result[\"final_label\"] = \"LIKELY_AUTHENTIC\"\n",
        "    else:\n",
        "        verdict_result[\"final_score\"] = ensemble_result[\"final_score\"]\n",
        "        verdict_result[\"final_label\"] = ensemble_result[\"final_label\"]\n",
        "        verdict_result[\"confidence\"] = min(verdict_result.get(\"confidence\", 0.5), 0.6)\n",
        "else:\n",
        "    verdict_result[\"final_score\"] = ensemble_result[\"final_score\"]\n",
        "    verdict_result[\"final_label\"] = ensemble_result[\"final_label\"]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL VERDICT\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Label: {verdict_result['final_label']}\")\n",
        "print(f\"Score: {verdict_result['final_score']:.4f}\")\n",
        "print(f\"Confidence: {verdict_result.get('confidence', 0.0):.2%}\")\n",
        "print(f\"Reasons: {', '.join(verdict_result.get('reason', []))}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Visualize verdict\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "label = verdict_result['final_label']\n",
        "score = verdict_result['final_score']\n",
        "\n",
        "# Color based on verdict\n",
        "if 'MANIPULATED' in label:\n",
        "    color = 'red'\n",
        "elif 'AUTHENTIC' in label:\n",
        "    color = 'green'\n",
        "else:\n",
        "    color = 'orange'\n",
        "\n",
        "ax.barh([0], [score], color=color, alpha=0.7, height=0.5)\n",
        "ax.axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Threshold')\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_xlabel('Manipulation Score', fontsize=12)\n",
        "ax.set_title(f'Final Verdict: {label}', fontsize=14, fontweight='bold')\n",
        "ax.text(score, 0, f'{score:.3f}', ha='center', va='center', fontsize=14, fontweight='bold')\n",
        "ax.set_yticks([])\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Generate Abnormality Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate abnormality report\n",
        "# Initialize variables if not set\n",
        "if 'face_count' not in locals():\n",
        "    face_count = 0\n",
        "if 'faces_output_dir' not in locals():\n",
        "    faces_output_dir = None\n",
        "if 'detections' not in locals():\n",
        "    detections = []\n",
        "if 'temporal_mean' not in locals():\n",
        "    temporal_mean = 0.5\n",
        "if 'temporal_max' not in locals():\n",
        "    temporal_max = 0.5\n",
        "if 'lip_sync_score' not in locals():\n",
        "    lip_sync_score = None\n",
        "if 'aggregation_result' not in locals():\n",
        "    aggregation_result = {}\n",
        "\n",
        "abnormality_report = None\n",
        "technique_report = None\n",
        "\n",
        "if face_count > 0 and faces_output_dir and Path(faces_output_dir).exists():\n",
        "    try:\n",
        "        print(\"Generating abnormality report...\")\n",
        "        abnormality_analyzer = AbnormalityAnalyzer()\n",
        "        abnormality_report = abnormality_analyzer.generate_abnormality_report(\n",
        "            faces_dir=faces_output_dir,\n",
        "            detections=detections,\n",
        "            temporal_mean=temporal_mean,\n",
        "            temporal_max=temporal_max,\n",
        "            lip_sync_score=lip_sync_score\n",
        "        )\n",
        "        \n",
        "        print(f\"✓ Abnormality report generated\")\n",
        "        print(f\"  Spatial artifacts: {len(abnormality_report.get('spatial_artifacts', []))}\")\n",
        "        \n",
        "        # Generate technique identification\n",
        "        print(\"\\nIdentifying deepfake creation technique...\")\n",
        "        technique_identifier = TechniqueIdentifier()\n",
        "        technique_report = technique_identifier.generate_technique_report(\n",
        "            abnormality_report=abnormality_report,\n",
        "            aggregation=aggregation_result\n",
        "        )\n",
        "        \n",
        "        if technique_report.get(\"primary_technique\"):\n",
        "            primary = technique_report['primary_technique']\n",
        "            print(f\"✓ Primary technique: {primary['name']}\")\n",
        "            print(f\"  Confidence: {primary['confidence']:.1%}\")\n",
        "        else:\n",
        "            print(\"⚠ No specific technique identified\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Error generating reports: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"⚠ No faces to analyze\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Complete Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate complete result\n",
        "# Initialize variables if not set\n",
        "if 'job_id' not in locals() or job_id is None:\n",
        "    job_id = str(uuid.uuid4()) if 'uuid' in dir() else \"test\"\n",
        "if 'video_path' not in locals():\n",
        "    video_path = \"storage/uploads/your_video.mp4\"\n",
        "if 'frame_count' not in locals():\n",
        "    frame_count = 0\n",
        "if 'detections' not in locals():\n",
        "    detections = []\n",
        "if 'lip_sync_score' not in locals():\n",
        "    lip_sync_score = None\n",
        "if 'temporal_mean' not in locals():\n",
        "    temporal_mean = 0.5\n",
        "if 'temporal_max' not in locals():\n",
        "    temporal_max = 0.5\n",
        "if 'abnormality_report' not in locals():\n",
        "    abnormality_report = None\n",
        "if 'technique_report' not in locals():\n",
        "    technique_report = None\n",
        "if 'verdict_result' not in locals():\n",
        "    verdict_result = {\"final_label\": \"INCONCLUSIVE\", \"final_score\": 0.5, \"confidence\": 0.0}\n",
        "if 'results_dir' not in locals():\n",
        "    results_dir = os.path.abspath(\"results\")\n",
        "\n",
        "result = aggregation.generate_result(\n",
        "    job_id=job_id,\n",
        "    video_path=video_path,\n",
        "    frames=frame_count,\n",
        "    detections=detections,\n",
        "    lip_sync_score=lip_sync_score,\n",
        "    temporal_mean=temporal_mean,\n",
        "    temporal_max=temporal_max,\n",
        "    abnormality_report=abnormality_report,\n",
        "    technique_report=technique_report\n",
        ")\n",
        "\n",
        "# Update with ensemble verdict\n",
        "result[\"verdict\"] = verdict_result\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPLETE RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Job ID: {job_id}\")\n",
        "print(f\"Video: {video_path}\")\n",
        "print(f\"Frames extracted: {result['frames']}\")\n",
        "print(f\"Faces detected: {result['faces']}\")\n",
        "print(f\"\\nFinal Verdict: {result['verdict']['final_label']}\")\n",
        "print(f\"Final Score: {result['verdict']['final_score']:.4f}\")\n",
        "print(f\"Confidence: {result['verdict'].get('confidence', 0.0):.2%}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save result to JSON\n",
        "result_file = Path(results_dir) / f\"{job_id}.json\"\n",
        "result_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "with open(result_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "print(f\"\\n✓ Results saved to: {result_file}\")\n",
        "\n",
        "# Display top suspicious faces\n",
        "if detections:\n",
        "    print(\"\\nTop 5 Most Suspicious Faces:\")\n",
        "    for i, det in enumerate(detections[:5], 1):\n",
        "        print(f\"  {i}. Frame {det['frame']}: Score = {det['fake_score']:.4f}\")\n",
        "\n",
        "# Pretty print JSON result\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Full Result JSON:\")\n",
        "print(\"=\"*60)\n",
        "result_json = json.dumps(result, indent=2, ensure_ascii=False)\n",
        "if len(result_json) > 2000:\n",
        "    print(result_json[:2000] + \"...\")\n",
        "else:\n",
        "    print(result_json)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Visualization of Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualization\n",
        "# Initialize variables if not set\n",
        "if 'detections' not in locals():\n",
        "    detections = []\n",
        "if 'aggregation_result' not in locals():\n",
        "    aggregation_result = {'max_score': 0.5, 'frequency_score': 0.5, 'temporal_max': 0.5}\n",
        "if 'lip_sync_score' not in locals():\n",
        "    lip_sync_score = None\n",
        "if 'verdict_result' not in locals():\n",
        "    verdict_result = {\"final_label\": \"INCONCLUSIVE\", \"final_score\": 0.5}\n",
        "if 'face_count' not in locals():\n",
        "    face_count = 0\n",
        "if 'faces_output_dir' not in locals():\n",
        "    faces_output_dir = None\n",
        "\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# 1. Score timeline\n",
        "ax1 = fig.add_subplot(gs[0, :])\n",
        "if detections:\n",
        "    frames = [d['frame'] for d in detections]\n",
        "    scores = [d['fake_score'] for d in detections]\n",
        "    ax1.plot(frames, scores, 'o-', color='steelblue', linewidth=2, markersize=6)\n",
        "    ax1.axhline(y=0.5, color='r', linestyle='--', linewidth=2, label='Threshold')\n",
        "    ax1.set_xlabel('Frame Number')\n",
        "    ax1.set_ylabel('Fake Score')\n",
        "    ax1.set_title('CNN Fake Scores Over Time', fontsize=12, fontweight='bold')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Detector comparison\n",
        "ax2 = fig.add_subplot(gs[1, 0])\n",
        "detector_names = ['CNN Max', 'Frequency', 'Temporal Max', 'Lip-Sync']\n",
        "detector_scores = [\n",
        "    aggregation_result['max_score'],\n",
        "    aggregation_result['frequency_score'],\n",
        "    aggregation_result['temporal_max'],\n",
        "    1.0 - lip_sync_score if lip_sync_score else 0.5\n",
        "]\n",
        "colors = ['red' if s > 0.5 else 'green' for s in detector_scores]\n",
        "ax2.barh(detector_names, detector_scores, color=colors, alpha=0.7)\n",
        "ax2.axvline(x=0.5, color='black', linestyle='--', linewidth=1)\n",
        "ax2.set_xlim([0, 1])\n",
        "ax2.set_xlabel('Score')\n",
        "ax2.set_title('Detector Scores', fontsize=11, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 3. Score distribution\n",
        "ax3 = fig.add_subplot(gs[1, 1])\n",
        "if detections:\n",
        "    scores = [d['fake_score'] for d in detections]\n",
        "    ax3.hist(scores, bins=15, edgecolor='black', alpha=0.7, color='coral')\n",
        "    ax3.axvline(x=0.5, color='r', linestyle='--', linewidth=2, label='Threshold')\n",
        "    ax3.set_xlabel('Fake Score')\n",
        "    ax3.set_ylabel('Frequency')\n",
        "    ax3.set_title('Score Distribution', fontsize=11, fontweight='bold')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Final verdict\n",
        "ax4 = fig.add_subplot(gs[1, 2])\n",
        "label = verdict_result['final_label']\n",
        "score = verdict_result['final_score']\n",
        "if 'MANIPULATED' in label:\n",
        "    verdict_color = 'red'\n",
        "elif 'AUTHENTIC' in label:\n",
        "    verdict_color = 'green'\n",
        "else:\n",
        "    verdict_color = 'orange'\n",
        "ax4.barh([0], [score], color=verdict_color, alpha=0.8, height=0.3)\n",
        "ax4.axvline(x=0.5, color='black', linestyle='--', linewidth=2)\n",
        "ax4.set_xlim([0, 1])\n",
        "ax4.set_xlabel('Final Score')\n",
        "ax4.set_title(f'Final Verdict\\n{label}', fontsize=11, fontweight='bold')\n",
        "ax4.text(score, 0, f'{score:.3f}', ha='center', va='center', fontsize=12, fontweight='bold')\n",
        "ax4.set_yticks([])\n",
        "ax4.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 5. Sample faces with scores\n",
        "if detections and face_count > 0:\n",
        "    # Show top 3 most suspicious faces\n",
        "    top_faces = detections[:3]\n",
        "    face_files = sorted(Path(faces_output_dir).glob(\"face_*.jpg\"))\n",
        "    \n",
        "    for idx, det in enumerate(top_faces):\n",
        "        # Find corresponding face file\n",
        "        face_file = next((f for f in face_files if f.name == det['face_file']), None)\n",
        "        if face_file:\n",
        "            img = Image.open(face_file)\n",
        "            ax5_sub = fig.add_subplot(gs[2, idx])\n",
        "            ax5_sub.imshow(img)\n",
        "            ax5_sub.set_title(f\"Frame {det['frame']}\\nScore: {det['fake_score']:.3f}\", \n",
        "                            fontsize=10, fontweight='bold',\n",
        "                            color='red' if det['fake_score'] > 0.5 else 'green')\n",
        "            ax5_sub.axis('off')\n",
        "\n",
        "plt.suptitle('Deepfake Detection Analysis Report', fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Analysis complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
